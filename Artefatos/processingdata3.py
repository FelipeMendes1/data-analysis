# -*- coding: utf-8 -*-
"""processingdata3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Su12-srqAStFEW-1Cyr6c0qy1skwwsQw
"""

import pandas as pd

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('2021-2022.csv')

df

df.head()

df.tail()

df.columns

df.dtypes

df['Date'] = pd.to_datetime(df['Date'])

df.dtypes

df.info()

df.describe()

df.isnull().sum()

df.dropna(inplace=True)

df.drop_duplicates(inplace = True)

import matplotlib as plt
import seaborn as sns

df['HTOa'].apply(lambda x: type(x)).value_counts()

#convertendo valores não convertíveis para NaN
df['HTOa'] = pd.to_numeric(df['HTOa'], errors='coerce')

df['HTOa'].fillna(df['HTOa'].mean(), inplace=True)

from scipy import stats
import numpy as np


numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
data = df[(np.abs(stats.zscore(df[numeric_cols])) < 3).all(axis=1)]

data

df = data

df

#verificando estacionaridade
from statsmodels.tsa.stattools import adfuller

adf_result = adfuller(data['FTHG'])
print('ADF Statistic: %f' % adf_result[0])
print('p-value: %f' % adf_result[1])

##concluímos que é uma série estacionária

#vamos dividir os dados em conjuntos de treinamento e teste(80% treinamento,20% teste)
train_size = int(len(data) * 0.8)
train_data = data.iloc[:train_size]
test_data = data.iloc[train_size:]

def cria_dataset(series, look_back=1):
    X, Y = [], []
    for i in range(len(series) - look_back):
        a = series[i:(i + look_back)]
        X.append(a)
        Y.append(series[i + look_back])
    return np.array(X), np.array(Y)

#número de jogos passados que queremos usar para prever o próximo
look_back = 1

#aplicando a função para criar datasets de treino e teste
X_train, y_train = cria_dataset(train_data['FTHG'].values, look_back)
X_test, y_test = cria_dataset(test_data['FTHG'].values, look_back)

from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV
import numpy as np

#agora vamos procurar os melhores hiperparâmetros para nossos modelos

#definimos o modelo SVR
svr = SVR()

#definimos o grid de hiperparâmetros para procurar
param_grid_svr = {
    'kernel': ['rbf', 'linear'],
    'C': [0.1, 1, 10, 100],
    'gamma': ['auto', 'scale', 0.01, 0.1, 1],
    'epsilon': [0.01, 0.1, 0.5, 1]
    }

#configuramos o GridSearchCV para SVR
grid_search_svr = GridSearchCV(estimator=svr,param_grid=param_grid_svr, cv=5, n_jobs=-1,verbose=2)

#fit do GridSearchCV
grid_search_svr.fit(X_train, y_train)

#melhores parâmetros e melhor pontuação para SVR
print("Melhores parâmetros para SVR: ",grid_search_svr.best_params_)
print("Melhor pontuação para SVR: ",grid_search_svr.best_score_)

#definimos o modelo MLP
mlp = MLPRegressor(max_iter=1000)

#definimos o grid de hiperparâmetros para procurar
param_grid_mlp = {
    'hidden_layer_sizes': [(50,), (100,), (50,50)],
    'activation': ['tanh', 'relu'],
    'solver': ['sgd', 'adam'],
    'alpha': [0.0001, 0.001, 0.01],
    'learning_rate': ['constant', 'adaptive'],
}

#configuramos o GridSearchCV para MLP
grid_search_mlp = GridSearchCV(estimator=mlp, param_grid=param_grid_mlp, cv=5, n_jobs=-1, verbose=2)

#fit do GridSearchCV
grid_search_mlp.fit(X_train, y_train)

#melhores parâmetros e melhor pontuação para MLP
print("Melhores parâmetros para MLP: ", grid_search_mlp.best_params_)
print("Melhor pontuação para MLP: ", grid_search_mlp.best_score_)

#configuração e treinamento dos modelos com os melhores hiperparâmetros

from sklearn.metrics import mean_squared_error
import numpy as np

#configuramos e treinamos o MLP com os melhores parâmetros
mlp_best = MLPRegressor(
    activation='tanh',
    alpha=0.01,
    hidden_layer_sizes=(50, 50),
    learning_rate='adaptive',
    solver='adam',
    max_iter=1000
)
mlp_best.fit(X_train, y_train)

#fazer previsões com o mlp
mlp_predictions = mlp_best.predict(X_test)

#avaliando o desempenho do MLP usando RMSE
mlp_rmse = np.sqrt(mean_squared_error(y_test, mlp_predictions))
print("RMSE para MLP: ", mlp_rmse)

#configurando e treinando o SVR com os melhores parâmetros
svr_best = SVR(
    C=0.1,
    epsilon=0.5,
    gamma='auto',
    kernel='linear'
)
svr_best.fit(X_train, y_train)

#fazendo previsões com o svr
svr_predictions = svr_best.predict(X_test)

#avaliando o desempenho do SVR usando RMSE
svr_rmse = np.sqrt(mean_squared_error(y_test, svr_predictions))
print("RMSE para SVR: ", svr_rmse)

